{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e4ea1a-c5af-43e5-a3d4-ef75dccc285d",
   "metadata": {},
   "source": [
    "# Supervised Learning : Classification Task\n",
    "## Multiclass Classification : iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82227a08-e1cf-46ef-9e57-755103afd560",
   "metadata": {},
   "source": [
    "## Context "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2018ed-d090-46de-af09-ddfb04c3e5a8",
   "metadata": {},
   "source": [
    "Suppose you are a data scientist working at a horticultural company that specializes in growing various species of flowers, including different varieties of Iris. The company is interested in using machine learning to automate the identification process of the Iris flowers based on their features (sepal length, sepal width, petal length, petal width) to improve efficiency in their supply chain and inventory management.\n",
    "\n",
    "Your task is to build a machine learning model that can accurately classify the variety of Iris flower based on these given features. To do this, you're going to use the famous Iris dataset, which has measurements for 150 Iris flowers from three different species.\n",
    "\n",
    "You've decided to start with two well-known classification algorithms: Decision Tree and Random Forest. Your goal is to train these models, evaluate their performance, and then enhance their performance using hyperparameter tuning techniques (GridSearchCV and RandomizedSearchCV).\n",
    "\n",
    "The ultimate goal is to deliver the best possible model that can accurately identify and categorize the Iris flowers, thus aiding the company in their automated identification process.\n",
    "\n",
    "By the end of this activity, you'll have a clear understanding of how to implement these algorithms, evaluate their performance, and optimize them for better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e50e2a-e140-4e1c-9a5b-8daca3914194",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11f7e6a3-5fe8-4868-97fa-044f7bcf030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7abe60-9168-4b7a-b486-f77cac749101",
   "metadata": {},
   "source": [
    "These lines import the necessary libraries for our machine learning task. We import pandas and numpy for data handling, sklearn's datasets module to load the Iris dataset, sklearn's model_selection module for splitting the dataset into training and testing sets and for hyperparameter tuning, DecisionTreeClassifier and RandomForestClassifier for our models, and several metrics for evaluating our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2782f4f-33b1-41e4-b299-9c20fd96fd1d",
   "metadata": {},
   "source": [
    "## 2. load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec0404a-75c4-4567-98c8-bb7b65747ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98610045-5318-43e2-b0ef-37c29f623b17",
   "metadata": {},
   "source": [
    "We load the Iris dataset, which is included in sklearn's datasets module. We separate the features and the target variable into X and y, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1860c7fc-27db-417e-b9a0-8bf225a75371",
   "metadata": {},
   "source": [
    "## 3. Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3a2e2c-9a29-414a-aade-42e7f94c0941",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb095e-2e6e-4180-9bcf-f8ff5875bcac",
   "metadata": {},
   "source": [
    "We split the data into training and testing sets. We reserve 80% of the data for training and 20% for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2203e-416f-40ad-87fd-95b2d0cc68a5",
   "metadata": {},
   "source": [
    "## 4. Train and Evaluate a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "294f0881-a015-466f-a921-0a3615fb94ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "predictions = dt.predict(X_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print('Accuracy:', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63235b5-4771-46bd-b596-91f36cad4bd3",
   "metadata": {},
   "source": [
    "We create a Decision Tree classifier, fit it to our training data, and make predictions on the test data. We then print the classification report, the confusion matrix, and the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28949fd7-bed2-4170-b9aa-b6f38b89618b",
   "metadata": {},
   "source": [
    "### Evaluating Decision Tree Classifier using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85496d72-86be-4d07-833f-85ac9858e3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score for Random Forest:  0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "scores_dt = cross_val_score(dt, X, y, cv=5) # Evaluating in all data iris.data, iris.target on 5 folds\n",
    "print(\"Average cross-validation score for Random Forest: \", scores_dt.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a2126-cde0-4b62-9f33-69e05967ba53",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate a Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f24d17cf-ebd5-4cb4-902f-aeca69bd24ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print('Accuracy:', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d7ec1c-b234-4a29-b1d2-d9b04693127b",
   "metadata": {},
   "source": [
    "We create a Random Forest classifier, fit it to our training data, and make predictions on the test data. We then print the classification report, the confusion matrix, and the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cd0e32-c852-4be8-b07c-27bfc52f5d2f",
   "metadata": {},
   "source": [
    "### Evaluating Random Forest Classifier using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a12371b-f37a-4732-8459-16fbbc1d5e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score for Random Forest:  0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "scores_rf = cross_val_score(rf, X, y, cv=5) # Evaluating in all data iris.data, iris.target\n",
    "print(\"Average cross-validation score for Random Forest: \", scores_rf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed61ea93-a1fa-435b-a9dd-43b31bedcf7c",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa4e1d3a-719e-4917-8018-183681f7541a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Score: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best Parameters:', grid_search.best_params_)\n",
    "print('Best Score:', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394a8282-d90c-4159-ad95-bf43af993f89",
   "metadata": {},
   "source": [
    "We define a grid of hyperparameters to search over. We then use GridSearchCV with 5-fold cross-validation on our Random Forest classifier to find the best hyperparameters. We fit GridSearchCV to our training data and print the best hyperparameters and the best score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa954514-f2ed-46ee-889a-5fbd58bb8dbc",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af438fcb-bce1-4a86-8900-e7655d900847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 50, 'min_samples_split': 5, 'max_depth': 10}\n",
      "Best Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "random_search = RandomizedSearchCV(rf, param_dist, cv=5, scoring='accuracy')\n",
    "random_search.fit(X_train, y_train)\n",
    "print('Best Parameters:', random_search.best_params_)\n",
    "print('Best Score:', random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3181761c-48a0-44d4-866a-4de3c0fb92df",
   "metadata": {},
   "source": [
    "Like GridSearchCV, we define a distribution of hyperparameters to search over. We then use RandomizedSearchCV with 5-fold cross-validation on our Random Forest classifier to find the best hyperparameters. We fit RandomizedSearchCV to our training data and print the best hyperparameters and the best score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4237c73-4d76-45a8-8fe8-e191d9a63045",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39211657-b2c5-4c77-ba1c-57ed6e349eca",
   "metadata": {},
   "source": [
    "Cross-validation can be computationally expensive, especially with large datasets or complex models. So, you might need to balance the benefits of a more accurate estimate of model performance with the computational cost of cross-validation.\n",
    "\n",
    "\n",
    "The choice between `GridSearchCV` and `RandomizedSearchCV` really depends on your computational resources, the number of hyperparameters you need to tune, and your familiarity with the hyperparameters.\n",
    "If you only have a few hyperparameters to tune and you have sufficient computational resources, `GridSearchCV` might be the best option. If you have many hyperparameters to tune, or if computational resources are limited, `RandomizedSearchCV` could be a more efficient choice. Also, if you're not sure about the range of values a hyperparameter should take, random search can be a better starting point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
