{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d32eb59-909f-4335-89af-e97443c2e4f3",
   "metadata": {},
   "source": [
    "# Model Tuning and Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce74f04b-eb08-47cc-b06e-ca5c0450f4ed",
   "metadata": {},
   "source": [
    "This tutorial provides an introduction to the critical aspects of model tuning and improvement in classification and regression tasks. Key topics covered include hyperparameter tuning techniques such as grid search and random search, feature selection and engineering, ensemble methods and handling unbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecad3b0-914a-4963-8a43-b185e99ee1f5",
   "metadata": {},
   "source": [
    "## I. Model Tuning and Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b41f53-1379-4905-b1e2-ad8910094327",
   "metadata": {},
   "source": [
    "Model tuning and improvement involve adjusting and fine-tuning the parameters of a model to optimize its performance, reduce errors, and make it more accurate and reliable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746cf499-b667-47e2-89f7-71584b453ca9",
   "metadata": {},
   "source": [
    "### 1. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6fe82-b7f3-4c87-8053-8ae8f34a47d9",
   "metadata": {},
   "source": [
    "Hyperparameters are the settings or configurations of a model that are external to the model and cannot be learned from the training process. They need to be configured before training. Examples include the learning rate, the depth of trees in a random forest, and the number of hidden layers in a neural network.\n",
    "\n",
    "Tuning hyperparameters is a crucial step because the right set of hyperparameters can significantly improve the model's performance. Techniques used for hyperparameter tuning include:\n",
    "\n",
    "- **Grid Search:** Grid search is a traditional way to perform hyperparameter optimization, i.e., it exhaustively tries every combination of the provided hyper-parameter values to find the best model. The main disadvantage of this method is the computational cost, particularly when dealing with a large number of different hyperparameters and much bigger datasets.\n",
    "\n",
    "- **Random Search:** Random search differs from grid search mainly in that it does not try every single combination of hyperparameters. Instead, it randomly selects combinations of hyperparameters to train the model and evaluate performance. Given the same resources, it allows for a wider exploration of hyperparameters compared to grid search.\n",
    "\n",
    "We use Grid Search when the hyperparameter space is relatively small and computationally manageable, whereas we use Random Search when the hyperparameter space is large, and we want to explore as many different combinations as possible given a time constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f5b042-d925-4e16-9dce-d4e66888c8ff",
   "metadata": {},
   "source": [
    "**Examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ca817-90e6-4f4d-842e-5c38b6452680",
   "metadata": {},
   "source": [
    "Let's consider an example using Decision Tree and Random Forest algorithms. Here we will perform hyperparameter tuning for both algorithms using GridSearchCV and RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e087c-4bd6-4475-a92f-23bdfaca6ba4",
   "metadata": {},
   "source": [
    "- **Decision Tree algorithm**\n",
    "\n",
    "Decision Tree algorithm has a number of hyperparameters that can be tuned for better performance. Here are some of them along with a brief description:\n",
    "\n",
    "    - max_depth: The maximum depth of the tree. This is a major way to control overfitting as higher depth will allow the model to learn relations very specific to a particular sample.\n",
    "\n",
    "    - min_samples_split: The minimum number of samples required to split an internal node. This can vary between considering at least one sample at each node to considering all of the samples at each node. When we increase this parameter, the tree becomes more constrained as it has to consider more samples at each node.\n",
    "\n",
    "    - min_samples_leaf: The minimum number of samples required to be at a leaf node. This parameter is similar to min_samples_splits, however, this describe the minimum number of samples of samples at the leafs, the base of the tree.\n",
    "\n",
    "    - max_features: The number of features to consider when looking for the best split. This is a key parameter when dealing with a high-dimensional dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1117d8c-24b8-4d72-863c-519141796e10",
   "metadata": {},
   "source": [
    "- **Random Forest**\n",
    "\n",
    "Random Forest is a type of ensemble machine learning model that consists of a large number of individual decision trees. Here are some of the key hyperparameters for a Random Forest:\n",
    "\n",
    "    - n_estimators: The number of trees in the forest. Generally, the more trees, the better the performance, but also the more computational resources it requires.\n",
    "\n",
    "    - max_depth: The maximum depth of each tree. This can help control overfitting.\n",
    "\n",
    "    - min_samples_split: The minimum number of samples required to split an internal node in each decision tree.\n",
    "\n",
    "    - min_samples_leaf: The minimum number of samples required to be at a leaf node in each decision tree.\n",
    "\n",
    "    - max_features: The number of features to consider when looking for the best split. This can be an integer, float, string or None.\n",
    "\n",
    "    - bootstrap: Whether bootstrap samples are used when building trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1092693e-244f-4b78-890a-564cda44952e",
   "metadata": {},
   "source": [
    "Let's illustrate how to tune these hyperparameters for a Decision Tree Classifier and Random Forest Classifier using Grid Search and Random search on the iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3654539-8707-48f3-b052-319ce9d461df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Grid Search Best Params:  {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Decision Tree - Random Search Best Params:  {'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Decision Tree hyperparameters\n",
    "dt_param_grid = {\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Random Forest hyperparameters\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 4, 6, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Grid Search for Decision Tree\n",
    "dt_grid_search = GridSearchCV(dt, dt_param_grid)\n",
    "dt_grid_search.fit(iris.data, iris.target)\n",
    "print(\"Decision Tree - Grid Search Best Params: \", dt_grid_search.best_params_)\n",
    "\n",
    "# Random Search for Decision Tree\n",
    "dt_random_search = RandomizedSearchCV(dt, dt_param_grid)\n",
    "dt_random_search.fit(iris.data, iris.target)\n",
    "print(\"Decision Tree - Random Search Best Params: \", dt_random_search.best_params_)\n",
    "\n",
    "# Grid Search for Random Forest\n",
    "rf_grid_search = GridSearchCV(rf, rf_param_grid)\n",
    "rf_grid_search.fit(iris.data, iris.target)\n",
    "print(\"Random Forest - Grid Search Best Params: \", rf_grid_search.best_params_)\n",
    "\n",
    "# Random Search for Random Forest\n",
    "rf_random_search = RandomizedSearchCV(rf, rf_param_grid)\n",
    "rf_random_search.fit(iris.data, iris.target)\n",
    "print(\"Random Forest - Random Search Best Params: \", rf_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3295cb39-913b-4f4a-a20b-e3d8f9e8c7f1",
   "metadata": {},
   "source": [
    "In this script, we define separate dictionaries of parameters to tune for the Decision Tree and Random Forest classifiers. We then initialize GridSearchCV and RandomizedSearchCV objects for each classifier and fit them to our data. The best performing hyperparameters are then printed.\n",
    "\n",
    "**Note:** in a real-world scenario, you'd also want to split your data into training and testing sets and assess the performance of your model using unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e67a120-279c-4540-9ae8-e93bdaff9260",
   "metadata": {},
   "source": [
    "### 2. Feature Selection and Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c71983-5b3f-43e1-aef9-a2edb05fb808",
   "metadata": {},
   "source": [
    "#### 1. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c171ff0-d5b1-4e3e-a784-e6a767afa539",
   "metadata": {},
   "source": [
    "Feature selection is the process of identifying the most important features for a given model. This reduces the complexity of a model, improves its performance, and reduces overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e0811-c3cb-47d3-8b5e-42526f9db3fb",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a92f849-ff74-4c0a-bbae-8ef25715b4f2",
   "metadata": {},
   "source": [
    "We'll use the mutual information method for feature selection. Mutual information measures the dependency between two variables: the greater the value, the higher the dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d64f0d-5800-4e46-ae78-e00e678ac2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:  ['MedInc', 'AveRooms', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load California Housing dataset\n",
    "dataset = fetch_california_housing()\n",
    "X, y = dataset.data, dataset.target\n",
    "feature_names = dataset.feature_names\n",
    "\n",
    "# Use mutual information for feature selection\n",
    "selector = SelectKBest(score_func=mutual_info_regression, k=4) \n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "selected_features = [feature_names[i] for i in range(len(selector.get_support())) if selector.get_support()[i]]\n",
    "print('Selected Features: ', selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e34121-23e8-402d-8aea-80f1ecdff819",
   "metadata": {},
   "source": [
    "This script selects the top 4 features that have the highest mutual information with the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4934f3c5-d6c6-4347-8d07-42bc6baa1998",
   "metadata": {},
   "source": [
    "#### 2. Features Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432fe85-7e92-45e2-aecb-43f179c8a2da",
   "metadata": {},
   "source": [
    "Feature engineering is the process of creating new features or transforming existing ones to improve model performance. This can involve a wide range of techniques, from simple mathematical transformations to complex domain-specific methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749f1eba-b95e-4f25-bec5-b1fd875fc611",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d40e3f8-ee8d-4d35-812c-816e4f04e192",
   "metadata": {},
   "source": [
    "A common technique for feature engineering is the creation of polynomial features, which are new features created from the original features raised to the power of the degree specified. Let's create a quadratic feature from the `AveRooms` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98da8367-7a56-4234-aa5b-53d4318387d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "      <th>AveRooms_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "      <td>48.778030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "      <td>38.914354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "      <td>68.693192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "      <td>33.841580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "      <td>39.461681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  AveRooms_2  \n",
       "0    -122.23        4.526   48.778030  \n",
       "1    -122.22        3.585   38.914354  \n",
       "2    -122.24        3.521   68.693192  \n",
       "3    -122.25        3.413   33.841580  \n",
       "4    -122.25        3.422   39.461681  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load California Housing dataset\n",
    "dataset = fetch_california_housing(as_frame=True)\n",
    "df= dataset.frame\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "df['AveRooms_2'] = poly.fit_transform(df[['AveRooms']])[:, 1]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee49f7-0096-46dc-8c1e-64437af174f7",
   "metadata": {},
   "source": [
    "In this script, we're creating a new feature `AveRooms_2` which is the square of `AveRooms`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a59d8-918f-4e6e-9fe0-921c0afc0124",
   "metadata": {},
   "source": [
    "**Note:** these are very basic examples and the choice of feature selection and feature engineering methods will highly depend on the problem at hand, the dataset, and the model being used. It's always a good practice to validate the performance of the features using a hold-out set or cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d69287-b701-4a1e-aad0-a1bcd9dbb10b",
   "metadata": {},
   "source": [
    "### 3. Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf92e2-e90e-4a9b-88f0-7cb80f015cdf",
   "metadata": {},
   "source": [
    "Ensemble methods involve combining the decisions from multiple models to improve the overall performance. They can help make the model more robust and prevent overfitting. There are several types of ensemble methods:\n",
    "\n",
    "- **Bagging (Bootstrap Aggregating):** This technique involves creating multiple subsets of the original data (with replacement), training a model on each, and combining the outputs. An example is the Random Forest algorithm.\n",
    "\n",
    "- **Boosting:** This technique trains models in sequence where each new model corrects the errors made by the previous ones. Examples include Gradient Boosting and AdaBoost.\n",
    "\n",
    "- **Stacking:** This involves training multiple different models and using another machine learning model to combine their outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a085c-d350-4841-9b73-cf78476d7d06",
   "metadata": {},
   "source": [
    "**Examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b731a947-a124-4596-9281-33fafe2cc5e4",
   "metadata": {},
   "source": [
    "Let's take a look at examples for each type of ensemble method using the Scikit-learn library: Bagging, Boosting, and Stacking.\n",
    "\n",
    "In each of these examples, the models are trained on the Iris dataset. The models are evaluated by calculating the accuracy of their predictions on a hold-out test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3986337-e0c5-4e47-8799-2ef9346e0f33",
   "metadata": {},
   "source": [
    "- **Bagging (Bootstrap Aggregating):** Bagging uses the idea of bootstrap sampling to create different subsets of the original dataset, trains a model on each subset, and combines the outputs. The most common example is the Random Forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b09f45-b0e3-4edc-882d-2416b5934a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Random Forest Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0a7ef-f94f-4ccc-ac54-38113caa665e",
   "metadata": {},
   "source": [
    "- **Boosting:** Boosting trains models in sequence with each model learning from the errors of its predecessor. Here's an example using Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ac9e55c-dcd1-42e8-bc39-d75b672f2743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = gb.predict(X_test)\n",
    "print(\"Gradient Boosting Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccfd370-0ee5-4333-a60e-acbe9c1033bd",
   "metadata": {},
   "source": [
    "- **Stacking (Stacked Generalization):** Stacking involves training a model (the \"meta-learner\") to combine the predictions of several other models. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2805f026-27f2-4420-8108-8439bd1022e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the base models\n",
    "base_models = [\n",
    "                ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "                ('gb', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42))\n",
    "               ]\n",
    "\n",
    "# Initialize Stacking Classifier with a Logistic Regression as the meta-learner\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "print(\"Stacking Classifier Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9113d-4bd0-4604-99b9-565b47f71c13",
   "metadata": {},
   "source": [
    "### 4. Handling Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c06a9-5972-4ff4-8be8-0ab8c076d779",
   "metadata": {},
   "source": [
    "In classification problems, it's common to have imbalanced classes, i.e., one class has significantly more samples than the other. This can lead to poor performance for the minority class. Techniques to handle imbalanced data include:\n",
    "\n",
    "- **Oversampling:** This involves increasing the number of instances in the minority class by randomly replicating them in order to present a higher representation.\n",
    "\n",
    "- **Undersampling:** This refers to reducing the data of the majority class, bringing balance to the dataset.\n",
    "\n",
    "- **SMOTE (Synthetic Minority Over-sampling Technique):** This is a combination of oversampling and undersampling, but the oversampling approach is not by replicating minority class but constructing new minority class data instance via an algorithm.\n",
    "\n",
    "**Note:** these techniques don't always improve results. It's essential to validate performance with a hold-out test set to ensure the tuning steps have improved your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95400515-b634-41c1-b18f-c9c28d8531ce",
   "metadata": {},
   "source": [
    "**Examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d584918-c334-4e6e-acd1-bb8ff4ce9e99",
   "metadata": {},
   "source": [
    "Here is a demonstration of two methods for handling imbalanced data using simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd5207-9bea-481b-90fc-486b6fb32dec",
   "metadata": {},
   "source": [
    "**1. Over-sampling the minority class using SMOTE (Synthetic Minority Over-sampling Technique)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fad71c8e-c532-48f0-93f7-108a2c4f2f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       197\n",
      "           1       0.33      0.67      0.44         3\n",
      "\n",
      "    accuracy                           0.97       200\n",
      "   macro avg       0.66      0.82      0.72       200\n",
      "weighted avg       0.98      0.97      0.98       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a binary classification dataset with imbalanced class distribution\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10,\n",
    "                           n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Random Forest classifier on the over-sampled data\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_sm, y_sm)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f17f0bd-428f-4e78-ac24-20dfd8bcf249",
   "metadata": {},
   "source": [
    "If you get the error `ModuleNotFoundError: No module named 'imblearn'`, you need to install the imblearn library. You can install it by uncommenting and executing the following code cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7596f044-cde7-430e-8b65-0d43870edd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0370bb-7b4d-4db0-b607-ca8faa75cb2b",
   "metadata": {},
   "source": [
    "**2. Under-sampling the majority class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb1ba150-949d-43f0-ad4a-1165e6ba9e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93       197\n",
      "           1       0.10      1.00      0.18         3\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.55      0.93      0.55       200\n",
      "weighted avg       0.99      0.86      0.92       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Apply under-sampling to the training data\n",
    "undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_us, y_us = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Random Forest classifier on the under-sampled data\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_us, y_us)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33504e44-b284-40ac-8c2b-82ca704fb944",
   "metadata": {},
   "source": [
    "In both examples, the model has been trained on a balanced version of the training set but is tested on the original, imbalanced test set to provide a realistic evaluation of its performance.\n",
    "\n",
    "Imbalanced datasets are common in fraud detection scenarios where fraud cases represent a minority compared to the normal cases. Rou can apply this demonstration using the Synthetic Financial Datasets For Fraud Detection from the Kaggle platform which is a simulated dataset that is structurally similar to real-world credit card transaction data.\n",
    "\n",
    "The dataset can be downloaded here: https://www.kaggle.com/datasets/ealaxi/paysim1\n",
    "\n",
    "Notes : \n",
    "- Keep in mind that over-sampling increases the likelihood of overfitting since it replicates the minority class examples, and under-sampling can lead to loss of information. It's best to use a combination of these methods and always validate the results using a hold-out test set.\n",
    "\n",
    "- in real-life scenarios, data needs to be carefully preprocessed, and the model's performance should be thoroughly evaluated, ideally using multiple metrics and not solely relying on accuracy as it can be misleading when dealing with imbalanced data. The precision, recall, F1 score, and the confusion matrix are good indicators to use when dealing with imbalanced datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
